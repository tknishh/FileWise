{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Dependencies\n",
    "# !pip install transformers\n",
    "# !pip install openai\n",
    "\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from transformers import GPT3LMHeadModel, GPT3Tokenizer\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "\n",
    "# Step 2: Fine-tune the DPR Model\n",
    "# Assuming you have your training data in 'train_data' variable\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "# Prepare your data and fine-tune your model\n",
    "# This is a high-level representation, you need to adjust according to your data\n",
    "\n",
    "# Step 3: Retrieve Relevant Passages\n",
    "# Assuming 'user_question' is the question asked by the user\n",
    "question_inputs = question_tokenizer(user_question, return_tensors='pt')\n",
    "question_outputs = question_encoder(**question_inputs)\n",
    "question_embedding = question_outputs.pooler_output\n",
    "\n",
    "# Calculate similarity scores and select top-k passages\n",
    "\n",
    "# Step 4: Fine-tune the GPT-3.5 Model\n",
    "# Assuming you have your API key in 'api_key' variable\n",
    "gpt_model = GPT3LMHeadModel.from_pretrained('gpt3.5-turbo', api_key=api_key)\n",
    "gpt_tokenizer = GPT3Tokenizer.from_pretrained('gpt3.5-turbo')\n",
    "\n",
    "# Prepare your data and fine-tune your model\n",
    "\n",
    "# Step 5: Generate Answers\n",
    "# Assuming 'context' is the retrieved context\n",
    "inputs = gpt_tokenizer.encode(user_question + context, return_tensors='pt')\n",
    "outputs = gpt_model.generate(inputs)\n",
    "answer = gpt_tokenizer.decode(outputs[0])\n",
    "\n",
    "# Step 6: Evaluate Answers\n",
    "# Assuming 'reference_answer' is the correct answer for the user question\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(answer, reference_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Dependencies\n",
    "# !pip install transformers\n",
    "# !pip install openai\n",
    "# !pip install rouge\n",
    "\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from transformers import GPT3LMHeadModel, GPT3Tokenizer\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "\n",
    "# Step 2: Fine-tune the DPR Model\n",
    "train_data = [\n",
    "    {\"question\": \"What is the capital of France?\", \"passage\": \"The capital of France is Paris.\"},\n",
    "    {\"question\": \"Who wrote the Harry Potter series?\", \"passage\": \"The Harry Potter series was written by J.K. Rowling.\"}\n",
    "]\n",
    "\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "# Prepare training data\n",
    "train_inputs = []\n",
    "for data in train_data:\n",
    "    question_inputs = question_tokenizer(data[\"question\"], return_tensors='pt')\n",
    "    question_outputs = question_encoder(**question_inputs)\n",
    "    question_embedding = question_outputs.pooler_output\n",
    "\n",
    "    context_inputs = context_tokenizer(data[\"passage\"], return_tensors='pt')\n",
    "    context_outputs = context_encoder(**context_inputs)\n",
    "    context_embedding = context_outputs.pooler_output\n",
    "\n",
    "    train_inputs.append((question_embedding, context_embedding))\n",
    "\n",
    "# Fine-tune the model\n",
    "# ...\n",
    "\n",
    "# Step 3: Retrieve Relevant Passages\n",
    "user_question = \"What is the capital of France?\"\n",
    "\n",
    "question_inputs = question_tokenizer(user_question, return_tensors='pt')\n",
    "question_outputs = question_encoder(**question_inputs)\n",
    "question_embedding = question_outputs.pooler_output\n",
    "\n",
    "# Calculate similarity scores and select top-k passages\n",
    "# ...\n",
    "\n",
    "# Step 4: Fine-tune the GPT-3.5 Model\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "gpt_model = GPT3LMHeadModel.from_pretrained('gpt3.5-turbo', api_key=api_key)\n",
    "gpt_tokenizer = GPT3Tokenizer.from_pretrained('gpt3.5-turbo')\n",
    "\n",
    "# Prepare training data\n",
    "# ...\n",
    "\n",
    "# Fine-tune the model\n",
    "# ...\n",
    "\n",
    "# Step 5: Generate Answers\n",
    "context = \"The capital of France is Paris.\"\n",
    "\n",
    "inputs = gpt_tokenizer.encode(user_question + context, return_tensors='pt')\n",
    "outputs = gpt_model.generate(inputs)\n",
    "answer = gpt_tokenizer.decode(outputs[0])\n",
    "\n",
    "# Step 6: Evaluate Answers\n",
    "reference_answer = \"The capital of France is Paris.\"\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(answer, reference_answer)\n",
    "\n",
    "print(\"Generated Answer:\", answer)\n",
    "print(\"ROUGE Scores:\", scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
