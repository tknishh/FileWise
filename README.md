# FileWise: Empowering Insights, Effortlessly!

## Introduction
In this project, I will build a chatbot using the Retrieval Augmented Generation (RAG) approach. The RAG module consists of two main phases: retrieval and generation. The retrieval phase retrieves relevant context from a knowledge document based on the user's question, and the generation phase uses a language model to generate a personalized answer using the retrieved knowledge. The goal is to create a chatbot that can accurately answer user questions from the provided knowledge document while preventing hallucination.

## Approach

### Retrieval Phase
For the retrieval phase, I will use a dense vector-based retriever called DPR (Dense Passage Retriever). DPR is a dual-encoder model that encodes both the document passages and the user questions into fixed-length vectors. It then retrieves the most relevant passages based on the similarity between the question and the passages.

To implement DPR, I will use the pretrained DPR model provided in the Hugging Face library. I will fine-tune the model on the given knowledge document using a Siamese-style training setup. The training data will consist of pairs of (question, passage) where the passage is a relevant passage for the question.

Once the DPR model is fine-tuned, I will use it to retrieve relevant passages for a given user question. The top-k passages with the highest similarity scores will be selected as the retrieved context for the generation phase.

### Generation Phase
For the generation phase, I will use a Language Model (LM) to generate the answer based on the retrieved context. Specifically, I will use the GPT-3.5 model, which is a powerful autoregressive language model capable of generating coherent and contextually relevant text.

To implement the generation phase, I will use the GPT-3.5 model provided by OpenAI. I will input the user question along with the retrieved context from the retrieval phase to the model and generate the answer. To ensure that the generated answer is relevant and coherent, I will fine-tune the GPT-3.5 model on a combination of the provided data and synthetic data generated by annotating the relevance of question-answer pairs.

During fine-tuning, I will use a combination of maximum likelihood estimation and reinforcement learning with a reward model that encourages relevant and informative answers while penalizing irrelevant or hallucinated answers. This will help prevent hallucination and improve the overall accuracy of the generated answers.

### Evaluation of Answers
To evaluate the relevance of the answers generated by the chatbot, I will use a metric called ROUGE (Recall-Oriented Understudy for Gisting Evaluation). ROUGE measures the overlap between the generated answer and a set of reference answers based on n-gram co-occurrence statistics. I will calculate the ROUGE scores for the generated answers using the provided reference answers and use it as a measure of answer quality.

## Assumptions
- The knowledge document contains sufficient information to answer user questions.
- The user questions are within the scope of the knowledge document.
- The chatbot will be a text-based interface.
- The chatbot will handle one user question at a time.

## Future Scope
- Improve retrieval performance by using more advanced models like DPR with passage re-ranking.
- Explore different generation techniques, such as controlled text generation or leveraging pretraining on domain-specific data.
- Enhance the chatbot's conversational abilities by incorporating dialogue management techniques and context tracking.
- Deploy the chatbot as a web application or integrate it into existing chat platforms.
- Incorporate feedback loops to continuously improve the chatbot's performance and address user queries.
- Expand the knowledge base and keep it up to date with the latest information.

## Conclusion
In this project, I proposed a solution to build a chatbot using the Retrieval Augmented Generation (RAG) approach. The chatbot combines the retrieval phase, powered by a pretrained DPR model, to retrieve relevant context from a knowledge document, and the generation phase, powered by the GPT-3.5 language model, to generate personalized answers based on the retrieved context. By fine-tuning the models and evaluating the answers using ROUGE, we can improve the accuracy and relevance of the generated answers. The solution can be further enhanced by incorporating advanced retrieval and generation techniques, improving conversational abilities, and expanding the knowledge base.
